{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import math\n",
    "import operator\n",
    "import re\n",
    "from sklearn import decomposition, feature_selection, metrics, model_selection\n",
    "\n",
    "#nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.045</td>\n",
       "      <td>30.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            6.2              0.32         0.16             7.0      0.045   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 30.0                 136.0   0.9949  3.18       0.47   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8      6.0  \n",
       "1      9.5      6.0  \n",
       "2     10.1      6.0  \n",
       "3      9.9      6.0  \n",
       "4      9.6      6.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_train_f = open('Wine/wine_train.csv','r')\n",
    "wine_test_f = open('Wine/wine_test.csv','r')\n",
    "wine_train_lines = []\n",
    "wine_test_lines = []\n",
    "\n",
    "\n",
    "for line_num, line in enumerate(wine_train_f):\n",
    "    if line_num == 0:\n",
    "        line = line.replace('\"','')\n",
    "        line = line.replace('\\n','')\n",
    "        wine_train_lines.append(line.split(';'))\n",
    "    else:\n",
    "        n_line = line.split(';')\n",
    "        n_line = [float(x) for x in n_line]\n",
    "        wine_train_lines.append(n_line)\n",
    "        \n",
    "for line_num, line in enumerate(wine_test_f):\n",
    "    if line_num == 0:\n",
    "        line = line.replace('\"','')\n",
    "        wine_test_lines.append(line.split(';'))\n",
    "    else:\n",
    "        n_line = line.split(';')\n",
    "        n_line = [float(x) for x in n_line]\n",
    "        wine_test_lines.append(n_line)\n",
    "        \n",
    "w_train = pd.DataFrame(wine_train_lines[1:], columns=wine_train_lines[0])\n",
    "w_test = pd.DataFrame(wine_test_lines[1:], columns=wine_test_lines[0])\n",
    "\n",
    "train_array = w_train.values\n",
    "train_xs = [x[:-1] for x in train_array]\n",
    "train_ys = [y[-1:] for y in train_array]\n",
    "train_ys = np.reshape(train_ys, len(train_ys))\n",
    "\n",
    "test_array = w_test.values\n",
    "test_xs = [x[:-1] for x in test_array]\n",
    "test_ys = [y[-1:] for y in test_array]\n",
    "test_ys = np.reshape(test_ys, len(test_ys))\n",
    "\n",
    "w_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7743778617318132\n"
     ]
    }
   ],
   "source": [
    "lin_regress = sklearn.linear_model.LinearRegression()\n",
    "lin_regress.fit(train_xs, train_ys)\n",
    "preds_lin = lin_regress.predict(test_xs)\n",
    "\n",
    "print(math.sqrt(sklearn.metrics.mean_squared_error(y_true=test_ys, y_pred=preds_lin)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7263170196336258\n"
     ]
    }
   ],
   "source": [
    "svr_model = sklearn.svm.SVR(gamma=0.23, kernel='rbf')\n",
    "svr_model.fit(train_xs, train_ys)\n",
    "preds_svr = svr_model.predict(test_xs)\n",
    "\n",
    "print(math.sqrt(sklearn.metrics.mean_squared_error(test_ys, preds_svr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hateval = pd.read_csv('Hateval/hateval.tsv', sep='\\t')\n",
    "hateval.index = hateval['id']\n",
    "hateval = hateval.drop(['id'],axis=1)\n",
    "hateval.head()\n",
    "\n",
    "x = hateval.values\n",
    "pos_hat = [item[0] for item in x if item[1]==0]\n",
    "neg_hat = [item[0] for item in x if item[1]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_tokens(string):\n",
    "    sentence_split=nltk.tokenize.sent_tokenize(string)\n",
    "    list_tokens=[]\n",
    "    for sentence in sentence_split:\n",
    "        list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "        for token in list_tokens_sentence:\n",
    "            list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "            \n",
    "    return list_tokens\n",
    "\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "# We can add more words to the stopword list, like punctuation marks\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"#\")\n",
    "stopwords.add(\"@\")\n",
    "stopwords.add(\":\")\n",
    "stopwords.add(\"--\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"!\")\n",
    "stopwords.add(\"?\")\n",
    "stopwords.add(\"...\")\n",
    "stopwords.add(\"&\")\n",
    "stopwords.add(\"-\")\n",
    "stopwords.add(\";\")\n",
    "stopwords.add(\"'\")\n",
    "stopwords.add(\"#\")\n",
    "stopwords.add(\"â€™\")\n",
    "    \n",
    "    \n",
    "def get_vector_text(list_vocab,string):\n",
    "    vector_text=np.zeros(len(list_vocab))\n",
    "    list_tokens_string=get_list_tokens(string)\n",
    "    for i, word in enumerate(list_vocab):\n",
    "        if word in list_tokens_string:\n",
    "            vector_text[i]=list_tokens_string.count(word)\n",
    "    return vector_text\n",
    "\n",
    "def get_vocabulary(training_set, num_features): # Function to retrieve vocabulary\n",
    "    dict_word_frequency={}\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: continue\n",
    "            if word not in dict_word_frequency: dict_word_frequency[word]=1\n",
    "            else: dict_word_frequency[word]+=1\n",
    "    sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "        vocabulary.append(word)\n",
    "    return vocabulary\n",
    "\n",
    "def train_svm_classifier(training_set, vocabulary): # Function for training our svm classifier\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    for instance in training_set:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_train.append(vector_instance)\n",
    "        Y_train.append(instance[1])\n",
    "    # Finally, we train the SVM classifier \n",
    "    svm_clf=sklearn.svm.SVC(kernel=\"rbf\",gamma='scale')\n",
    "    svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n",
    "    return svm_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train, pos_test = sklearn.model_selection.train_test_split(pos_hat, train_size=0.7)\n",
    "neg_train, neg_test = sklearn.model_selection.train_test_split(neg_hat, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "Xvec_train = []\n",
    "\n",
    "X_test = []\n",
    "Y_test = []\n",
    "Xvec_test = []\n",
    "\n",
    "for pos_tweet in pos_train:\n",
    "    #vec = get_vector_text(vocabulary, pos_tweet)\n",
    "    X_train.append(pos_tweet)\n",
    "    Y_train.append(0)\n",
    "for neg_tweet in neg_train:\n",
    "    X_train.append(neg_tweet)\n",
    "    Y_train.append(1)\n",
    "    \n",
    "vocabulary = get_vocabulary(zip(X_train, Y_train), 1000)\n",
    "\n",
    "for pos_tweet in pos_train:\n",
    "    vec = get_vector_text(vocabulary, pos_tweet)\n",
    "    Xvec_train.append(vec)\n",
    "for neg_tweet in neg_train:\n",
    "    vec = get_vector_text(vocabulary, neg_tweet)\n",
    "    Xvec_train.append(vec)\n",
    "    \n",
    "for pos_tweet in pos_test:\n",
    "    vec = get_vector_text(vocabulary, pos_tweet)\n",
    "    X_test.append(pos_tweet)\n",
    "    Xvec_test.append(vec)\n",
    "    Y_test.append(0)\n",
    "for neg_tweet in neg_test:\n",
    "    vec = get_vector_text(vocabulary, neg_tweet)\n",
    "    X_test.append(pos_tweet)\n",
    "    Xvec_test.append(vec)\n",
    "    Y_test.append(1)\n",
    "    \n",
    "scaler = sklearn.preprocessing.Normalizer()\n",
    "std_x = scaler.fit_transform(Xvec_train)\n",
    "std_x_test = scaler.transform(Xvec_test)\n",
    "    \n",
    "svm_clf=train_svm_classifier(zip(X_train, Y_train), vocabulary)\n",
    "\n",
    "svm_clf_std = sklearn.svm.SVC(kernel='rbf', gamma='scale')\n",
    "svm_clf_std.fit(std_x, Y_train)\n",
    "\n",
    "chi_x = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=500).fit(Xvec_train, Y_train)\n",
    "Xvec_train_chi = chi_x.transform(Xvec_train)\n",
    "Xvec_test_chi = chi_x.transform(Xvec_test)\n",
    "\n",
    "svm_clf_chi = sklearn.svm.SVC(kernel='rbf', gamma='scale')\n",
    "svm_clf_chi.fit(Xvec_train_chi, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.82      1566\n",
      "           1       0.79      0.67      0.72      1135\n",
      "\n",
      "    accuracy                           0.78      2701\n",
      "   macro avg       0.79      0.77      0.77      2701\n",
      "weighted avg       0.79      0.78      0.78      2701\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83      1566\n",
      "           1       0.79      0.67      0.73      1135\n",
      "\n",
      "    accuracy                           0.79      2701\n",
      "   macro avg       0.79      0.77      0.78      2701\n",
      "weighted avg       0.79      0.79      0.78      2701\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.83      1566\n",
      "           1       0.78      0.68      0.73      1135\n",
      "\n",
      "    accuracy                           0.79      2701\n",
      "   macro avg       0.79      0.77      0.78      2701\n",
      "weighted avg       0.79      0.79      0.79      2701\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = svm_clf.predict(Xvec_test)\n",
    "preds_std = svm_clf_std.predict(std_x_test)\n",
    "preds_chi = svm_clf_chi.predict(Xvec_test_chi)\n",
    "print(sklearn.metrics.classification_report(Y_test, preds))\n",
    "print(sklearn.metrics.classification_report(Y_test, preds_std))\n",
    "print(sklearn.metrics.classification_report(Y_test, preds_chi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello world.', 'My name is Cai.', 'Nice to meet you']\n",
      "['hello', 'world', '.', 'my', 'name', 'is', 'cai', '.', 'nice', 'to', 'meet', 'you']\n"
     ]
    }
   ],
   "source": [
    "s = \"Hello world. My name is Cai. Nice to meet you\"\n",
    "x = nltk.tokenize.sent_tokenize(s)\n",
    "print(x)\n",
    "y = []\n",
    "yy = []\n",
    "for z in x:\n",
    "    y = nltk.tokenize.word_tokenize(z)\n",
    "    l = nltk.stem.WordNetLemmatizer()\n",
    "    for j in y:\n",
    "        yy.append(l.lemmatize(j).lower())\n",
    "        \n",
    "print(yy)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 with K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold completed with a_score= 0.8133333333333334\n",
      "Fold completed with a_score= 0.7988888888888889\n",
      "Fold completed with a_score= 0.79\n",
      "Fold completed with a_score= 0.7733333333333333\n",
      "Fold completed with a_score= 0.7588888888888888\n",
      "Fold completed with a_score= 0.7722222222222223\n",
      "Fold completed with a_score= 0.7633333333333333\n",
      "Fold completed with a_score= 0.7566666666666667\n",
      "Fold completed with a_score= 0.7488888888888889\n",
      "Fold completed with a_score= 0.7188888888888889\n",
      "Accuracy scores\n",
      "[0.8133333333333334, 0.7988888888888889, 0.79, 0.7733333333333333, 0.7588888888888888, 0.7722222222222223, 0.7633333333333333, 0.7566666666666667, 0.7488888888888889, 0.7188888888888889]\n",
      "Recall scores\n",
      "[0.7318435754189944, 0.6789772727272727, 0.6717948717948717, 0.6897435897435897, 0.6305555555555555, 0.6717557251908397, 0.6568627450980392, 0.6135135135135135, 0.5520833333333334, 0.4497354497354497]\n",
      "Precision scores\n",
      "[0.7844311377245509, 0.7785016286644951, 0.8111455108359134, 0.7642045454545454, 0.729903536977492, 0.7764705882352941, 0.7859237536656891, 0.7491749174917491, 0.7969924812030075, 0.7906976744186046]\n",
      "F1 scores\n",
      "[0.7572254335260115, 0.7253414264036419, 0.7349228611500702, 0.7250673854447439, 0.676602086438152, 0.7203274215552524, 0.7156208277703604, 0.674591381872214, 0.6523076923076924, 0.5733558178752107]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "dataset_full = []\n",
    "for pos_tweet in pos_hat:\n",
    "    dataset_full.append((pos_tweet, 0))\n",
    "for neg_tweet in neg_hat:\n",
    "    dataset_full.append((neg_tweet, 1))\n",
    "    \n",
    "kf = sklearn.model_selection.KFold(n_splits = 10)\n",
    "random.shuffle(dataset_full)\n",
    "kf.get_n_splits(dataset_full)\n",
    "accuracy_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "f_list = []\n",
    "\n",
    "k_list = [1000,750,500,250,150,100,75,50,25,10]\n",
    "j=0\n",
    "\n",
    "for train_index, test_index in kf.split(dataset_full):\n",
    "    train_set_fold=[]\n",
    "    test_set_fold=[]\n",
    "    for i,instance in enumerate(dataset_full):\n",
    "        if i in train_index:\n",
    "            train_set_fold.append(instance)\n",
    "        else:\n",
    "            test_set_fold.append(instance)\n",
    "            \n",
    "    vocabulary_fold=get_vocabulary(train_set_fold, 1000)\n",
    "    X_train_fold = [get_vector_text(vocabulary_fold, x[0]) for x in train_set_fold]\n",
    "    Y_train_fold = [x[1] for x in train_set_fold]\n",
    "    \n",
    "    chi_x = sklearn.feature_selection.SelectKBest(sklearn.feature_selection.chi2, k=k_list[j]).fit(X_train_fold, Y_train_fold)\n",
    "    X_train_fold = chi_x.transform(X_train_fold)\n",
    "    j = j+1\n",
    "    \n",
    "    svm_clf_fold=sklearn.svm.SVC(kernel='rbf', gamma='scale')\n",
    "    svm_clf_fold.fit(X_train_fold, Y_train_fold)\n",
    "    \n",
    "    X_test_fold=[]\n",
    "    Y_test_fold=[]\n",
    "    \n",
    "    for instance in test_set_fold:\n",
    "        vector_instance=get_vector_text(vocabulary_fold,instance[0])\n",
    "        X_test_fold.append(vector_instance)\n",
    "        Y_test_fold.append(instance[1])\n",
    "        \n",
    "    Y_test_fold_gold=np.asarray(Y_test_fold)\n",
    "    X_test_fold=np.asarray(chi_x.transform(X_test_fold))\n",
    "    Y_test_predictions_fold=svm_clf_fold.predict(X_test_fold)\n",
    "\n",
    "    accuracy_list.append(sklearn.metrics.accuracy_score(Y_test_fold_gold, Y_test_predictions_fold))\n",
    "    recall_list.append(sklearn.metrics.recall_score(Y_test_fold_gold, Y_test_predictions_fold))\n",
    "    precision_list.append(sklearn.metrics.precision_score(Y_test_fold_gold, Y_test_predictions_fold))\n",
    "    f_list.append(sklearn.metrics.f1_score(Y_test_fold_gold, Y_test_predictions_fold))\n",
    "    \n",
    "    print (\"Fold completed with a_score=\",str(sklearn.metrics.accuracy_score(Y_test_fold_gold, Y_test_predictions_fold)))\n",
    "    \n",
    "\n",
    "print(\"Accuracy scores\")\n",
    "print(accuracy_list)\n",
    "print(\"Recall scores\")\n",
    "print(recall_list)\n",
    "print(\"Precision scores\")\n",
    "print(precision_list)\n",
    "print(\"F1 scores\")\n",
    "print(f_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7572254335260115\n",
      "0.7253414264036419\n",
      "0.7349228611500702\n",
      "0.7250673854447439\n",
      "0.676602086438152\n",
      "0.7203274215552524\n",
      "0.7156208277703604\n",
      "0.674591381872214\n",
      "0.6523076923076924\n",
      "0.5733558178752107\n"
     ]
    }
   ],
   "source": [
    "for x in f_list:\n",
    "    print(x)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
